{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15.fmm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shhuangmust/AI/blob/110-2/15.fmm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FMM 正向最大符合（Forward Maximum Matching)\n",
        "- 英文有明確的空格當作字詞分隔，因此很容易進行例如n-grams的操作。但是中文無明確的字詞分隔\n",
        "- 因此中文必須進行\"斷詞(分詞)\"的工作\n",
        "- 除了查字典進行斷詞工作外，FMM是從前向後，掃描句子中的字串，儘量找到詞典中較長的單字，作為分詞的結果\n",
        "- 本範例需上傳lexicon.txt 下載：https://raw.githubusercontent.com/joshhu/nlp_must2022/main/lexicon.txt\n"
      ],
      "metadata": {
        "id": "dHc2Zp_dziWh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymAuokmn6c0W",
        "outputId": "acaf3912-b052-4163-b68b-b94af9a3c161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "輸入句字：明新科技大學\n",
            "明\n",
            "新\n",
            "科技\n",
            "大學\n"
          ]
        }
      ],
      "source": [
        "def load_dict():\n",
        "    f = open(\"lexicon.txt\")\n",
        "    lexicon = set()\n",
        "    max_len = 0\n",
        "    for line in f:\n",
        "        word = line.strip()\n",
        "        lexicon.add(word)\n",
        "        if len(word) > max_len:\n",
        "            max_len = len(word)\n",
        "    f.close()\n",
        "\n",
        "    return lexicon, max_len\n",
        "\n",
        "def fmm_word_seg(sentence, lexicon, max_len):\n",
        "    begin = 0\n",
        "    end = min(begin + max_len, len(sentence))\n",
        "    words = []\n",
        "    while begin < end:\n",
        "        word = sentence[begin:end]\n",
        "        if word in lexicon or end - begin == 1:\n",
        "            words.append(word)\n",
        "            begin = end\n",
        "            end = min(begin + max_len, len(sentence))\n",
        "        else:\n",
        "            end -= 1\n",
        "    return words\n",
        "\n",
        "lexicon, max_len = load_dict()\n",
        "words = fmm_word_seg(input(\"輸入句字：\"), lexicon, max_len)\n",
        "\n",
        "for word in words:\n",
        "    print(word,) \n"
      ]
    }
  ]
}